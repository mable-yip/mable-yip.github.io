(this.webpackJsonpbase=this.webpackJsonpbase||[]).push([[0],{10:function(e,t){e.exports={pageSize:10,categoryPageSize:5,categoryType:{Journal:"Journal",Conference:"Conference",Book:"Book",Other:"Other"},layoutOption:{ALL_PUBLICATION:"All Publication",BY_CATEGORY:"By Category"},sortingOption:{TITLE:"Title",AUTHOR:"Author",YEAR:"Year"}}},69:function(e,t,a){},70:function(e,t,a){"use strict";a.r(t);var i,n,s,o,r,l=a(0),c=a(21),d=a.n(c),u=a(27),A=(a(53),a(54),a(55),a(56),a(9)),p=a(79),h=a(42),g=a(77),m=Object({NODE_ENV:"production",PUBLIC_URL:"",WDS_SOCKET_HOST:void 0,WDS_SOCKET_PATH:void 0,WDS_SOCKET_PORT:void 0,FAST_REFRESH:!0,REACT_APP_TEAM_HOMEPAGE:'{"teamId":"612b849beae47c89542bebca","aboutUs":[""]}',REACT_APP_TEAM_INFO:'{"_id":"612b849beae47c89542bebca","teamName":"test","orgName":"test","email":"pmyip@gmail.com"}',REACT_APP_TEAM_MEMBERS:'[{"_id":"612dc016de93cd7af48cc167","fullName":"rewgwe","position":"rgewrg","summary":"wergewrgwer"}]',REACT_APP_TEAM_PUBLICATIONS:'[{"_id":"612b8ad0de6d5573680cef16","authors":["Bo Yang","Zhenchang Xing","Xin Xia","Chunyang Chen","Deheng Ye","Shanping Li"],"title":"Don\u2019t Do That! Hunting Down Visual Design Smells in Complex UIs against Design Guidelines","link":"","description":"Just like code smells in source code, UI design has visual design smells. We study 93 don\u2019t-do-that guidelines in the Material Design, a complex design system created by Google. We find that these don\u2019t-guidelines go far beyond UI aesthetics, and involve seven general design dimensions (layout, typography, iconography, navigation, communication, color, and shape) and four component design aspects (anatomy, placement, behavior, and usage). Violating these guidelines results in visual design smells in UIs (or UI design smells). In a study of 60,756 UIs of 9,286 Android apps, we find that 7,497 UIs of 2,587 apps have at least one violation of some Material Design guidelines. This reveals the lack of developer training and tool support to avoid UI design smells. To fill this gap, we design an automated UI design smell detector (UIS-Hunter) that extracts and validates multi-modal UI information (component\xa0\u2026","yearPublished":"2021","citedBy":1,"category":{"type":"Other","categoryTitle":"","pages":"761-772","publisher":"IEEE","volume":"","issue":""},"teamId":"612b849beae47c89542bebca","__v":0,"createdAt":"2021-08-29T13:25:36.345Z","updatedAt":"2021-08-29T13:25:36.345Z","year":2021},{"_id":"612b8ad0de6d5573680cef1d","authors":["Tianming Zhao","Chunyang Chen","Yuanning Liu","Xiaodong Zhu"],"title":"GUIGAN: Learning to Generate GUI Designs Using Generative Adversarial Networks","link":"https://arxiv.org/pdf/2101.09978","description":"Graphical User Interface (GUI) is ubiquitous in almost all modern desktop software, mobile applications, and online websites. A good GUI design is crucial to the success of the software in the market, but designing a good GUI which requires much innovation and creativity is difficult even to well-trained designers. Besides, the requirement of the rapid development of GUI design also aggravates designers\u2019 working load. So, the availability of various automated generated GUIs can help enhance the design personalization and specialization as they can cater to the taste of different designers. To assist designers, we develop a model GUIGAN to automatically generate GUI designs. Different from conventional image generation models based on image pixels, our GUIGAN is to reuse GUI components collected from existing mobile app GUIs for composing a new design that is similar to natural-language generation. Our\xa0\u2026","yearPublished":"2021","citedBy":2,"category":{"type":"Other","categoryTitle":"","pages":"","publisher":"","volume":"","issue":""},"teamId":"612b849beae47c89542bebca","__v":0,"createdAt":"2021-08-29T13:25:36.346Z","updatedAt":"2021-08-29T13:25:36.346Z","year":2021},{"_id":"612b8ad0de6d5573680cef18","authors":["Qiuyuan Chen","Chunyang Chen","Safwat Hassan","Zhengchang Xing","Xin Xia","Ahmed E Hassan"],"title":"How Should I Improve the UI of My App? A Study of User Reviews of Popular Apps in the Google Play","link":"","description":"UI (User Interface) is an essential factor influencing users\u2019 perception of an app. However, it is hard for even professional designers to determine if the UI is good or not for end-users. Users\u2019 feedback (e.g., user reviews in the Google Play) provides a way for app owners to understand how the users perceive the UI. In this article, we conduct an in-depth empirical study to analyze the UI issues of mobile apps. In particular, we analyze more than 3M UI-related reviews from 22,199 top free-to-download apps and 9,380 top non-free apps in the Google Play Store. By comparing the rating of UI-related reviews and other reviews of an app, we observe that UI-related reviews have lower ratings than other reviews. By manually analyzing a random sample of 1,447 UI-related reviews with a 95% confidence level and a 5% interval, we identify 17 UI-related issues types that belong to four categories (i.e., \u201cAppearance\xa0\u2026","yearPublished":"2021","citedBy":3,"category":{"type":"Other","categoryTitle":"","pages":"1-38","publisher":"ACM","volume":"30","issue":"3"},"teamId":"612b849beae47c89542bebca","__v":0,"createdAt":"2021-08-29T13:25:36.346Z","updatedAt":"2021-08-29T13:25:36.346Z","year":2021},{"_id":"612b8ad0de6d5573680cef14","authors":["Yuhui Su","Zhe Liu","Chunyang Chen","Junjie Wang","Qing Wang"],"title":"OwlEyes-online: a fully automated platform for detecting and localizing UI display issues","link":"https://arxiv.org/pdf/2107.02364","description":"Graphical User Interface (GUI) provides visual bridges between software apps and end users. However, due to the compatibility of software or hardware, UI display issues such as text overlap, blurred screen, image missing always occur during GUI rendering on different devices. Because these UI display issues can be found directly by human eyes, in this paper, we implement an online UI display issue detection tool OwlEyes-Online, which provides a simple and easy-to-use platform for users to realize the automatic detection and localization of UI display issues. The OwlEyes-Online can automatically run the app and get its screenshots and XML files, and then detect the existence of issues by analyzing the screenshots. In addition, OwlEyes-Online can also find the detailed area of the issue in the given screenshots to further remind developers. Finally, OwlEyes-Online will automatically generate test reports with UI display issues detected in app screenshots and send them to users. The OwlEyes-Online was evaluated and proved to be able to accurately detect UI display issues. Tool Link: http://www.owleyes.online:7476 Github Link: https://github.com/franklinbill/owleyes Demo Video Link: https://youtu.be/002nHZBxtCY","yearPublished":"2021","citedBy":null,"category":{"type":"Other","categoryTitle":"","pages":"","publisher":"","volume":"","issue":""},"teamId":"612b849beae47c89542bebca","__v":0,"createdAt":"2021-08-29T13:25:36.345Z","updatedAt":"2021-08-29T13:25:36.345Z","year":2021},{"_id":"612b8ad0de6d5573680cef15","authors":["Bo Yang","Zhenchang Xing","Xin Xia","Chunyang Chen","Deheng Ye","Shanping Li"],"title":"UIS-Hunter: Detecting UI Design Smells in Android Apps","link":"","description":"Similar to code smells in source code, UI design has visual design smells that indicate violations of good UI design guidelines. UI design guidelines constitute design systems for a vast variety of products, platforms, and services. Following a design system, developers can avoid common design issues and pitfalls. However, a design system is often complex, involving various design dimensions and numerous UI components. Lack of concerns on GUI visual effect results in little support for detecting UI design smells that violate the design guidelines in a complex design system. In this paper, we propose an automated UI design smell detector named UIS-Hunter (UI design Smell Hunter). The tool is able to (i) automatically process UI screenshots or prototype files to detect UI design smells and generate reports, (ii) highlight the violated UI regions and list the material design guidelines that the found design smells\xa0\u2026","yearPublished":"2021","citedBy":null,"category":{"type":"Other","categoryTitle":"","pages":"89-92","publisher":"IEEE","volume":"","issue":""},"teamId":"612b849beae47c89542bebca","__v":0,"createdAt":"2021-08-29T13:25:36.345Z","updatedAt":"2021-08-29T13:25:36.345Z","year":2021},{"_id":"612b9a8e52fad35524a80356","authors":["Mulong Xie","Sidong Feng","Zhenchang Xing","Jieshan Chen","Chunyang Chen"],"title":"UIED: a hybrid tool for GUI element detection","link":"https://www.researchgate.net/profile/Mulong-Xie/publication/346170544_UIED_a_hybrid_tool_for_GUI_element_detection/links/5fbca13a458515b797641b72/UIED-a-hybrid-tool-for-GUI-element-detection.pdf","description":"Graphical User Interface (GUI) elements detection is critical for many GUI automation and GUI testing tasks. Acquiring the accurate positions and classes of GUI elements is also the very first step to conduct GUI reverse engineering or perform GUI testing. In this paper, we implement a User Iterface Element Detection (UIED), a toolkit designed to provide user with a simple and easy-to-use platform to achieve accurate GUI element detection. UIED integrates multiple detection methods including old-fashioned computer vision (CV) approaches and deep learning models to handle diverse and complicated GUI images. Besides, it equips with a novel customized GUI element detection methods to produce state-of-the-art detection results. Our tool enables the user to change and edit the detection result in an interactive dashboard. Finally, it exports the detected UI elements in the GUI image to design files that can be\xa0\u2026","yearPublished":"2020","citedBy":5,"category":{"type":"Book","categoryTitle":"Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","pages":"1655-1659","publisher":"","volume":"","issue":""},"teamId":"612b849beae47c89542bebca","__v":0,"createdAt":"2021-08-29T14:32:46.039Z","updatedAt":"2021-08-29T14:32:46.039Z","year":2020},{"_id":"612b9a8e52fad35524a8035b","authors":["Jieshan Chen","Chunyang Chen","Zhenchang Xing","Xiwei Xu","Liming Zhu","Guoqiang Li","Jinshui Wang"],"title":"Unblind Your Apps: Predicting Natural-Language Labels for Mobile GUI Components by Deep Learning","link":"https://arxiv.org/pdf/2003.00380","description":"According to the World Health Organization(WHO), it is estimated that approximately 1.3 billion people live with some forms of vision impairment globally, of whom 36 million are blind. Due to their disability, engaging these minority into the society is a challenging problem. The recent rise of smart mobile phones provides a new solution by enabling blind users\' convenient access to the information and service for understanding the world. Users with vision impairment can adopt the screen reader embedded in the mobile operating systems to read the content of each screen within the app, and use gestures to interact with the phone. However, the prerequisite of using screen readers is that developers have to add natural-language labels to the image-based components when they are developing the app. Unfortunately, more than 77% apps have issues of missing labels, according to our analysis of 10,408 Android\xa0\u2026","yearPublished":"2020","citedBy":29,"category":{"type":"Conference","categoryTitle":"42nd International Conference on Software Engineering (ICSE\u201920)","pages":"","publisher":"","volume":"","issue":""},"teamId":"612b849beae47c89542bebca","__v":0,"createdAt":"2021-08-29T14:32:46.040Z","updatedAt":"2021-08-29T14:32:46.040Z","year":2020},{"_id":"612b9a8e52fad35524a8035a","authors":["Jieshan Chen","Chunyang Chen","Zhenchang Xing","Xin Xia","Liming Zhu","John Grundy","Jinshui Wang"],"title":"Wireframe-based UI design search through image autoencoder","link":"https://arxiv.org/pdf/2103.07085","description":"UI design is an integral part of software development. For many developers who do not have much UI design experience, exposing them to a large database of real-application UI designs can help them quickly build up a realistic understanding of the design space for a software feature and get design inspirations from existing applications. However, existing keyword-based, image-similarity-based, and component-matching-based methods cannot reliably find relevant high-fidelity UI designs in a large database alike to the UI wireframe that the developers sketch, in face of the great variations in UI designs. In this article, we propose a deep-learning-based UI design search engine to fill in the gap. The key innovation of our search engine is to train a wireframe image autoencoder using a large database of real-application UI designs, without the need for labeling relevant UI designs. We implement our approach for\xa0\u2026","yearPublished":"2020","citedBy":15,"category":{"type":"Journal","categoryTitle":"ACM Transactions on Software Engineering and Methodology (TOSEM)","pages":"1-31","publisher":"ACM","volume":"29","issue":"3"},"teamId":"612b849beae47c89542bebca","__v":0,"createdAt":"2021-08-29T14:32:46.040Z","updatedAt":"2021-08-29T14:32:46.040Z","year":2020},{"_id":"612cc3423c0bce8c741d7d81","authors":["Sen Chen","Lingling Fan","Chunyang Chen","Ting Su","Wenhe Li","Yang Liu","Lihua Xu"],"title":"Storydroid: Automated generation of storyboard for Android apps","link":"https://arxiv.org/pdf/1902.00476","description":"Mobile apps are now ubiquitous. Before developing a new app, the development team usually endeavors painstaking efforts to review many existing apps with similar purposes. The review process is crucial in the sense that it reduces market risks and provides inspiration for app development. However, manual exploration of hundreds of existing apps by different roles (e.g., product manager, UI/UX designer, developer) in a development team can be ineffective. For example, it is difficult to completely explore all the functionalities of the app in a short period of time. Inspired by the conception of storyboard in movie production, we propose a system, StoryDroid, to automatically generate the storyboard for Android apps, and assist different roles to review apps efficiently. Specifically, StoryDroid extracts the activity transition graph and leverages static analysis techniques to render UI pages to visualize the storyboard\xa0\u2026","yearPublished":"2019","citedBy":30,"category":{"type":"Conference","categoryTitle":"2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","pages":"596-607","publisher":"IEEE","volume":"","issue":""},"teamId":"612b849beae47c89542bebca","__v":0,"createdAt":"2021-08-30T11:38:42.229Z","updatedAt":"2021-08-30T11:38:42.229Z","year":2019}]',REACT_APP_WEB_PAGES:'{"publicationOptions":{"layout":"By Category","sortBy":"Author"},"pages":["PUBLICATIONS","TEAM"],"_id":"612b9be4536abc9ba4848519","teamId":"612b849beae47c89542bebca","createdAt":"2021-08-29T14:38:28.525Z","updatedAt":"2021-08-31T11:26:33.791Z","__v":1}'});m.REACT_APP_DEBUG?(console.log("Running in DEBUG mode, hence using fake Team data"),i=[{_id:"fake_publication_1",title:"Auto-icon: An automated code generation tool for icon designs assisting in ui development",description:'"Approximately 50% of development resources are devoted to UI development tasks [8]. Occupied a large proportion of development resources, developing icons can be a time-consuming task, because developers need to consider not only effective implementation methods but also easy-to-understand descriptions. In this study, we define 100 icon classes through an iterative open coding for the existing icon design sharing website. Based on a deep learning model and computer vision methods, we propose an approach to automatically convert icon images to fonts with descriptive labels, thereby reducing the laborious manual effort for developers and facilitating UI development. We quantitatively evaluate the quality of our method in the real world UI development environment and demonstrate that our method offers developers accurate, efficient, readable, and usable code for icon images, in terms of saving 65.2 \u2026',category:{type:"BOOK",categoryTitle:"26th International Conference on Intelligent User Interfaces",issue:"",volume:"",pages:"56-69",publisher:""},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Sidong Feng","Suyu Ma","Jinzhong Yu","Chunyang Chen","TingTing Zhou","Yankun Zhen"],yearPublished:"2021"},{_id:"fake_publication_2",title:"Context-aware Personalized Crowdtesting Task Recommendation",description:"Crowdsourced software testing (short for crowdtesting) is a special type of crowdsourcing. It requires that crowdworkers master appropriate skill-sets and commit significant effort for completing a task. Abundant uncertainty may arise during a crowdtesting process due to imperfect information between the task requester and crowdworkers. For example, a worker frequently chooses tasks in an ad hoc manner in crowdtesting context, and an inappropriate task selection may lead to the worker's failing to detect any bugs, and significant testing effort unpaid and wasted. Recent studies have explored methods for supporting task requesters to make informed decisions on task pricing, worker recommendation, and so on. Unfortunately, very few study offers decision making support from the crowdworkers' perspectives. We motivate this study through a pilot study, revealing the large portion (74%) of unpaid crowdworkers' \u2026",category:{type:"JOURNAL",categoryTitle:"International Economics Journal",issue:"10.1",volume:"11.2",pages:"10",publisher:"IMF"},link:"https://www.imf.org/en/Home",authors:["Jeremy Buffet","Warren Graham"],yearPublished:"2021"},{_id:"fake_publication_3",title:"MULTI-PHACET-MULTIdimensional clinical phenotyping of hospitalised acute COPD ExacerbaTions",description:"Securing generative Arts through NFTs Lorem ipsum amet dolor sit amet, minim altera mucius an eum. Etiam feugiat laoreet tempor. Vestibulum vel facilisis odio, in ultricies ex. Nullam vitae lectus vitae arcu efficitur auctor id a sem. Mauris congue enim risus, eu gravida mi dignissim ut. Vestibulum tempus urna vel sem eleifend, quis aliquet ligula maximus. Vivamus sagittis dolor eu iaculis interdum. Morbi ex odio, ornare eget erat eu, dapibus accumsan elit. Fusce fermentum orci ante. Etiam dolor urna, dictum a diam nec, ornare tempor nunc. Curabitur imperdiet malesuada augue eget vestibulum. Legere antiopam definitiones nam an.",category:{type:"BOOK",categoryTitle:"The digital asset certification",issue:"",volume:"",pages:"15",publisher:"Yoshua Benjio"},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Yoshua Benjio"],yearPublished:"2017"},{_id:"fake_publication_4",title:"CONCORDANCE OF LARYNGOSCOPY AND DYNAMIC COMPUTERIZED TOMOGRAPHY LARYNX TO DIAGNOSE VOCAL CORD DYSFUNCTION ",description:"",category:{type:"CONFERENCE",categoryTitle:"RESPIROLOGY",issue:"",volume:"",pages:"102-102",publisher:"Yoshua Benjio"},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Kaibo Cao","Chunyang Chen","Sebastian Baltes","Christoph Treude","Xiang Chen"],yearPublished:"2017"},{_id:"fake_publication_5",title:"Rivaroxaban compared to placebo for the treatment of leg superficial vein thrombosis: a randomized trial",description:"The role of rivaroxaban in the treatment of leg superficial venous thrombosis (SVT) is uncertain. This article aims to determine if rivaroxaban is an effective and safe treatment for leg SVT. Patients with symptomatic leg SVT of at least 5\u2009cm length were randomized to 45 days of rivaroxaban 10\u2009mg daily or to placebo, and followed for a total of 90 days. Treatment failure (required a nonstudy anticoagulant; had proximal deep vein thrombosis or pulmonary embolism; or had surgery for SVT) at 90 days was the primary efficacy outcome. Secondary efficacy outcomes included leg pain severity, and venous disease-specific and general health-related quality of life over 90 days. Major bleeding at 90 days was the primary safety outcome. Poor enrollment led to the trial being stopped after 85 of the planned 600 patients were randomized to rivaroxaban (n\u2009=\u200943) or placebo (n\u2009=\u200942). One rivaroxaban and five placebo \u2026",category:{type:"OTHER",categoryTitle:"",issue:"",volume:"54",pages:"15",publisher:"Yoshua Benjio"},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Yoshua Benjio"],yearPublished:"2017"},{_id:"fake_publication_6",title:"Owl Eyes: Spotting UI Display Issues via Visual Understanding",description:"Etiam feugiat laoreet tempor. Vestibulum vel facilisis odio, in ultricies ex. Nullam vitae lectus vitae arcu efficitur auctor id a sem. Mauris congue enim risus, eu gravida mi dignissim ut. Vestibulum tempus urna vel sem eleifend, quis aliquet ligula maximus. Vivamus sagittis dolor eu iaculis interdum. Morbi ex odio, ornare eget erat eu, dapibus accumsan elit. Fusce fermentum orci ante. Etiam dolor urna, dictum a diam nec, ornare tempor nunc. Curabitur imperdiet malesuada augue eget vestibulum.  Securing generative Arts through NFTs. Lorem ipsum amet dolor sit amet, minim altera mucius an eum. Legere antiopam definitiones nam an.",category:{type:"CONFERENCE",categoryTitle:"The digital asset certification",issue:"",volume:"",pages:"15",publisher:"Yoshua Benjio"},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Yoshua Benjio","Yoshua Aenjio","Yoshua Cenjio","Yoshua Denjio","Yoshua Eenjio","Yoshua Fenjio","Yoshua Genjio","Yoshua Henjio","Yoshua Ienjio"],yearPublished:"2017"},{_id:"fake_publication_7",title:"Wireframe-based UI design search through image autoencoder",description:"Securing generative Arts through NFTs",category:{type:"CONFERENCE",categoryTitle:"The digital asset certification",issue:"",volume:"",pages:"15",publisher:"Yoshua Benjio"},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Yoshua Benjio"],yearPublished:"2017"}],n={twitterHandle:"elonmusk",orgName:"Monash",teamName:"MonTeam"},s=[{fullName:"John",position:"Chief Scientist",summary:"John is a chief scientist at MonTeam, working with the top government agencies to fight the pressing issues arising from climate change"},{fullName:"Yoshua Benjio",position:"Chief Data Scientist",summary:"Hailed as one of the founders of Deep Learning, Yoshua works at MonTeam to oversee strategic deep learning project designs"},{fullName:"Jeremy Buffet",position:"Chief Economist",summary:"Jeremy Buffet leads our macro-economic unit in predicting macro factors and their impact on society"}],o={aboutUs:["This is first paragraph.","This is second paragraph.","This is third paragraph."]},r={pages:["PUBLICATIONS","TEAM"],publicationOptions:{layout:"All Publication",sortBy:"Author"}}):(i=m.REACT_APP_TEAM_PUBLICATIONS?JSON.parse(m.REACT_APP_TEAM_PUBLICATIONS):[],n=m.REACT_APP_TEAM_INFO?JSON.parse(m.REACT_APP_TEAM_INFO):null,s=m.REACT_APP_TEAM_MEMBERS?JSON.parse(m.REACT_APP_TEAM_MEMBERS):[],o=m.REACT_APP_TEAM_HOMEPAGE?JSON.parse(m.REACT_APP_TEAM_HOMEPAGE):null,r=m.REACT_APP_WEB_PAGES?JSON.parse(m.REACT_APP_WEB_PAGES):[],m.REACT_APP_WEBSITE_TITLE);var b=a(48),f=a(38),y=a(78),v=a(81),j=a(1),O=function(e,t){var a=Object(l.useState)(1),i=Object(f.a)(a,2),n=i[0],s=i[1],o=Math.ceil(e.length/t),r=function(){s((function(e){return Math.min(e+1,o)}))},c=function(){s((function(e){return Math.max(e-1,1)}))};return{currentData:function(){if(e){var a=(n-1)*t,i=a+t;return e.slice(a,i)}},pagination:function(){for(var e=[],t=function(t){e.push(Object(j.jsx)(v.a.Item,{onClick:function(){return function(e){var t=Math.max(1,e);s(Math.min(t,o))}(t)},active:t===n,children:t},t))},a=1;a<=o;a++)t(a);return Object(j.jsx)("div",{style:{display:"flex",justifyContent:"center"},children:Object(j.jsxs)(v.a,{children:[Object(j.jsx)(v.a.Prev,{onClick:c,disabled:1===n}),e,Object(j.jsx)(v.a.Next,{onClick:r,disabled:n===o})]})})}}},T=a(80),I=function(e){var t=e.pub;return Object(j.jsxs)(T.a,{className:"publication-card",children:[Object(j.jsxs)(y.a.Toggle,{as:T.a.Header,eventKey:t._id,className:"publication-title-column",children:[Object(j.jsx)("div",{className:"pub-category-above-title",children:t.category.type}),Object(j.jsxs)("div",{className:"publication-title",children:[" ",t.title]}),Object(j.jsxs)("div",{className:"pub-year-below-title",children:[" ",t.yearPublished," "]})]}),Object(j.jsx)(y.a.Collapse,{eventKey:t._id,children:Object(j.jsxs)(T.a.Body,{className:"publication-body-column",children:[Object(j.jsx)("div",{className:"pub-body-subheader",children:"Authors"}),Object(j.jsx)("div",{className:"pub-body-content",children:t.authors.map((function(e){return"".concat(e)})).join(", ")}),Object(j.jsx)("div",{className:"pub-body-subheader",children:"Description"}),Object(j.jsx)("div",{className:"pub-body-content pub-body-paragraph",children:t.description}),Object(j.jsx)("div",{className:"pub-body-subheader",children:t.category.categoryTitle?t.category.type.charAt(0)+t.category.type.slice(1).toLowerCase():""}),Object(j.jsx)("div",{className:"pub-body-content",children:t.category.categoryTitle?t.category.categoryTitle+(t.category.issue?", Issue "+t.category.issue:"")+(t.category.volume?", Volume "+t.category.volume:"")+(t.category.pages?", Page "+t.category.pages:""):""}),Object(j.jsx)("div",{className:"pub-body-subheader",children:t.category.publisher?"Published by":null}),Object(j.jsx)("div",{className:"pub-body-content",children:t.category.publisher}),Object(j.jsx)("div",{className:"pub-body-subheader",children:t.link?"View at":null}),Object(j.jsx)("div",{className:"pub-body-content",children:Object(j.jsx)("a",{href:t.link,children:t.link})})]})})]})},x=a(10),w=function(e){var t=e.teamPublications,a=e.pageSize,i=O(t,a||x.pageSize),n=i.currentData,s=i.pagination;return Object(j.jsxs)("div",{className:"mb-5",children:[n().map((function(e){return Object(j.jsx)(I,{pub:e},e._id)})),s()]})},E=function(e){var t=e.teamPublications,a=function(e){var a=t.filter((function(t){return t.category.type===e}));return a.length>0&&Object(j.jsxs)(j.Fragment,{children:[Object(j.jsxs)("h3",{className:"text-center",children:[" ",e," "]}),Object(j.jsx)(w,{teamPublications:a,pageSize:x.categoryPageSize})]})};return Object.keys(x.categoryType).map((function(e,t){return Object(j.jsx)("div",{children:a(e)},t)}))},U=a(25),C=a(76),k=function(e){var t=e.options,a=e.setOptions,i=e.publications,n=e.sortPublications;return Object(j.jsxs)("div",{style:{display:"flex",justifyContent:"center"},children:[Object(j.jsxs)(C.a,{style:{marginRight:"3px"},children:[Object(j.jsxs)(C.a.Toggle,{variant:"light",className:"mb-2",children:["Layout: ",t.layout]}),Object(j.jsx)(C.a.Menu,{children:Object.keys(x.layoutOption).map((function(e,i){return Object(j.jsx)(C.a.Item,{as:"button",onClick:function(){return a(Object(U.a)(Object(U.a)({},t),{},{layout:x.layoutOption[e]}))},children:x.layoutOption[e]},i)}))})]}),Object(j.jsxs)(C.a,{style:{marginLeft:"3px"},children:[Object(j.jsxs)(C.a.Toggle,{variant:"light",className:"mb-2",children:["Sort by: ",t.sortBy]}),Object(j.jsxs)(C.a.Menu,{children:[Object.keys(x.sortingOption).map((function(e,s){return Object(j.jsx)(C.a.Item,{as:"button",value:x.sortingOption[e],onClick:function(s){a(Object(U.a)(Object(U.a)({},t),{},{sortBy:x.sortingOption[e]})),n(i,s.target.value)},children:x.sortingOption[e]},s)})),t.layout===x.layoutOption.BY_CATEGORY&&Object(j.jsx)(C.a.Item,{as:"button",value:"Category Title",onClick:function(e){a(Object(U.a)(Object(U.a)({},t),{},{sortBy:e.target.value})),n(i,e.target.value)},children:"Category Title"})]})]})]})},P=function(){var e=r.publicationOptions,t=Object(l.useState)(e||x.defaultOption),a=Object(f.a)(t,2),n=a[0],s=a[1],o=function(e,t){switch(t){case x.sortingOption.AUTHOR:e.sort((function(e,t){return e.authors[0].toLowerCase()>t.authors[0].toLowerCase()?1:-1}));break;case x.sortingOption.TITLE:e.sort((function(e,t){return e.title.toLowerCase()>t.title.toLowerCase()?1:-1}));break;case"Category Title":e.sort((function(e,t){return e.category.categoryTitle.toLowerCase()>t.category.categoryTitle.toLowerCase()?1:-1}));break;default:e.sort((function(e,t){return e.title.toLowerCase()>t.title.toLowerCase()?1:-1})),e.sort((function(e,t){return e.year>t.year?-1:1}))}return e},c=o(i,n.sortBy);return Object(j.jsxs)(l.Fragment,{children:[Object(j.jsx)(k,{options:n,setOptions:s,publications:c,sortPublications:o}),Object(j.jsx)(y.a,{children:function(){switch(n.layout){case x.layoutOption.BY_CATEGORY:return Object(j.jsx)(E,{teamPublications:i});default:return Object(j.jsx)(w,{teamPublications:i})}}()})]})},_=function(){return Object(j.jsxs)(l.Fragment,{children:[Object(j.jsx)(h.a,{className:"pages-top-padding text-center mt-3 mb-3",children:Object(j.jsx)("div",{className:"publication-pg-title",children:"Our Publications"})}),Object(j.jsx)(h.a,{fluid:!0,children:Object(j.jsx)(P,{})})]})},N=function(){var e=o;return Object(j.jsx)(l.Fragment,{children:Object(j.jsxs)(h.a,{fluid:!0,className:"pages-top-padding",children:[Object(j.jsx)("div",{className:"landing-center-title",children:"About Us"}),e.aboutUs.map((function(e){return Object(j.jsx)("div",{className:"landing-center-content",children:e})}))]})})},S=a(75),B=function(e){var t=e.member;return Object(j.jsxs)(T.a,{className:"team-card",children:[Object(j.jsx)(T.a.Img,{variant:"top",src:"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxMQEA4QEBEPEA4PDxAOEA0NDw8SDQ4PFRcWFhURFRYYKCggGBomGxYVITEhJSkrLi4uGR8zODMuNygtLisBCgoKDg0NDw0NDisZHxkrKysrKysrLSsrKysrKysrKysrKys3KysrKysrKysrKysrKysrKysrKysrKysrKysrK//AABEIAOEA4QMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAABQYCAwQBB//EADgQAQACAQEDBwsDAwUAAAAAAAABAgMRBSExBAYSUVJhcTJBYoGRkqGxwdHhExUiM0NyI0Jjc5P/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMsM2WKVm1p0rG+ZVbaO0rZZmN9cfmpHn77dYJvlO2sVN0TN59Dh7eDivzhnzY49d/wAIMVE3XnDPnxx6rz9nXyfbmO262tJ9LfX2wrIC80tExExMTE8JidYeqfyHl18M61nWvnpPkz9p71q5JymuWsWrO7zx54nqlFbgAAAAAAAAAAAAAAAAAAAAauVZuhS9+zWZ9fmBAbf5Z0r/AKcT/Gk7++/4+6JezOu+d8zvmeuXioAAAAO7Y/LP0skaz/C+lbd3VPqcIC9Dj2Tn6eGkzxiOjPjG7X5OxFAAAAAAAAAAAAAAAAAAEbzgvphmO1asfX6JJFc5P6Uf9kfKQVoBUAAAAAAWHmzf+GSvVaJ9sfhMoPmxwy+NPqnEUAAAAAAAAAAAAAAAAAAcG28fSwX666W9k7/hq73l6xMTE8JiYnwkFGGzlGGaXtSeNZ08eqfY1qgAAAAD2tZmYiN8zOkR1zPAFj5t49MVrdq8+yN33SzTyTB+nSlOzWInvnzz7W5FAAAAAAAAAAAAAAAAAAAAQ+3uQdOP1Kx/KsaWjtV6/GFdXpDbS2L0pm+LSLTvmk7qzPd1Arw2ZsNqTpes1nvjj4dbWqAMseObTpWJtPVWJmQYpvYHINZ/VtG6PIjrntPdnbE3xbNw4xjjz/5T9E7EaIr0AAAAAAAAAAAAAAAAAAAAY3vFY1tMRHXM6QjeUbcx18nW8+jGlfbIJQV3Lt+8+TWlfHW0/RzztrN2ojwrUFotSJ3TETHVMaw5r7NxT/br6o0+Sv8A7zm7ce7U/ec3bj3agsFdmYY/t19es/N048cV3ViKx1ViIj4Kt+85u3Hu1P3nN2492qi1iqxtnN2o92rdj29kjyq0t6piUFkERg29SfLranf5Vfhv+CTw563jWlotHdINgAAAAAAAAAAAAAAEyAidobarTWuPS9+HS/2V+7i2vtWb648c6U4WtHG/h3fNEA28o5TbJOt7TbunhHhHmagVAAAAAAAABnjyTWdazNZ66zpLABOcg25wrl/9Kx84+ydpeJiJiYmJ3xMcJUZ27N2jbDPXjmf5V+sd4LaMMOWL1i1Z1rMaxLNFAAAAAAAAAAEPzg5b0axjrO+8a27q9XrTCn7Ty9PLkn0piPCN0fIHKAqAAAAAAAAAAAAAAJbYHLejf9OZ/jfh6N/z9lkUattJiY4xMTHjC74r9KtbRwtET7UVkAAAAAAAAADHLfo1tbsxM+xR9Vv2tfTBln0dPbu+qoAAKgAAAAAAAAAAAAAAt2yL9LBinqr0fZu+iorPzdtrh07N7R8p+qKkwAAAAAAAAAR235/0Ld81j4qstHOH+hP+VVXEAFAAAAAAAAAAAAAABYubM/wyR6f0hXVg5s+Rk/yj5CpoBAAAAAAAABx7XxdLDkiOMR0o9U6qivSvbT2NNdb4o1rxmkca+HXHcCGAVAAAAAAAAAAAAAABZubuPTFr27TPqjSPpKH2bs62adeGOON+vujvWrFjisRWsaRWIiI7kVkAAAAAAAAAAADk5Zs7Hl32jS3brut+UNynYV430mLx1T/G32WQBSc2C1PLravjE6Na9TDky7NxW446+NY0n4AqAsuTYOOeE3r4TEx8XPfm91ZPbX8qIIS9ub+TzWxz4zaPownYWX/j9Vp+wiLEn+x5vQ978PY2Fl68fvT9gRYl6838nnvSPDpT9G+nN7tZPdr9wQIs+PYWKOPTt420j4OzByPHTyaVieuI3+0VV+T7OyZPJpOnatur8UvyPYVa6Tknpz2Y3U/KYEHla6RpG6I3REcIegAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD//Z"}),Object(j.jsxs)(T.a.Body,{children:[Object(j.jsx)("div",{className:"member-name",children:t.fullName}),Object(j.jsx)("div",{className:"member-position",children:t.position}),Object(j.jsx)("div",{className:"member-summary",children:t.summary})]})]})},M=[{title:"Publications",path:"/publication",exact:!0,component:_},{title:"Team",path:"/team",exact:!0,component:function(){var e=s;return Object(j.jsxs)(l.Fragment,{children:[Object(j.jsx)(h.a,{className:"pages-top-padding text-center mt-3 mb-3",children:Object(j.jsx)("div",{className:"team-pg-title",children:"Meet Our Team"})}),Object(j.jsx)(h.a,{fluid:!0,className:"team-card-container",children:Object(j.jsx)(S.a,{className:"team-card-deck",children:e.map((function(e){return Object(j.jsx)(B,{member:e},e._id)}))})})]})}}],G=[{title:"Home",path:"/",exact:!0,component:N}],L=function(){var e=M.filter((function(e){var t=e.title;return r.pages.includes(t.toUpperCase())}));return[].concat(G,Object(b.a)(e))},Y=function(){var e=n.orgName,t=n.teamName,a=L();return console.log(a),Object(j.jsx)(l.Fragment,{children:Object(j.jsx)(p.a,{collapseOnSelect:!0,expand:"md",bg:"light",variant:"light",fixed:"top",children:Object(j.jsxs)(h.a,{fluid:!0,children:[Object(j.jsxs)(p.a.Brand,{as:u.b,to:"/",children:[t," @ ",e]}),Object(j.jsx)(p.a.Toggle,{"aria-controls":"responsive-navbar-nav"}),Object(j.jsxs)(p.a.Collapse,{id:"responsive-navbar-nav",children:[Object(j.jsx)(g.a,{className:"me-auto"}),Object(j.jsx)(g.a,{children:a.map((function(e,t){var a=e.path,i=e.title;return Object(j.jsx)(g.a.Link,{as:u.b,to:a,children:i},t)}))})]})]})})})},R=(a(69),function(){console.log(r);var e=L().map((function(e){var t=e.path,a=e.exact,i=e.component;return Object(j.jsx)(A.a,{exact:a,path:t,children:Object(j.jsx)("div",{children:i?Object(j.jsx)(i,{}):null})},t)}));return Object(j.jsxs)(l.Fragment,{children:[Object(j.jsx)(Y,{}),Object(j.jsx)(A.c,{children:e})]})});d.a.render(Object(j.jsx)(u.a,{children:Object(j.jsx)(R,{})}),document.getElementById("root"))}},[[70,1,2]]]);
//# sourceMappingURL=main.9e27b885.chunk.js.map